{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/juliangreil/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/juliangreil/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import scipy\n",
    "import random\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')\n",
    "stop_words = stopwords.words('english')\n",
    "from langdetect import detect\n",
    "import re, string\n",
    "#from gensim.models.doc2vec import Doc2Vec\n",
    "#from sentence_transformers import SentenceTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import torch.autograd as autograd         # computation graph\n",
    "from torch import Tensor \n",
    "import torch# tensor node in the computation graph\n",
    "import torch.nn as nn                     # neural networks\n",
    "import torch.nn.functional as F           # layers, activations and more\n",
    "import torch.optim as optim   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tw_df = pd.read_csv(\"Twitter_Data.csv\")\n",
    "red_df = pd.read_csv(\"Reddit_Data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_text</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>when modi promised “minimum government maximum...</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>talk all the nonsense and continue all the dra...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>what did just say vote for modi  welcome bjp t...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>asking his supporters prefix chowkidar their n...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>answer who among these the most powerful world...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          clean_text  category\n",
       "0  when modi promised “minimum government maximum...      -1.0\n",
       "1  talk all the nonsense and continue all the dra...       0.0\n",
       "2  what did just say vote for modi  welcome bjp t...       1.0\n",
       "3  asking his supporters prefix chowkidar their n...       1.0\n",
       "4  answer who among these the most powerful world...       1.0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tw_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_comment</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>family mormon have never tried explain them t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>buddhism has very much lot compatible with chr...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>seriously don say thing first all they won get...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>what you have learned yours and only yours wha...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>for your own benefit you may want read living ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       clean_comment  category\n",
       "0   family mormon have never tried explain them t...         1\n",
       "1  buddhism has very much lot compatible with chr...         1\n",
       "2  seriously don say thing first all they won get...        -1\n",
       "3  what you have learned yours and only yours wha...         0\n",
       "4  for your own benefit you may want read living ...         1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "red_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "red_df.dropna(inplace = True, how = \"any\")\n",
    "tw_df.dropna(inplace = True, how = \"any\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_list = []\n",
    "for i, row in red_df.iterrows():\n",
    "    data_list.append((row[\"clean_comment\"].split(),row[\"category\"]))\n",
    "for i, row in tw_df.iterrows():\n",
    "    data_list.append((row[\"clean_text\"].split(),row[\"category\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_list.append((\"Hier steht einfach mal was deutsches\".split(),0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['️️️️️️️️️️️️️️️', '️️️️️️️️️️️️️️', '️️️️️️️️️️️', '️️️️️️️️️️', '️️️️️️️️️', '️️️️️️️️', '️️️️️️️', '️️️️️️️️️', '️️️️️️️️️️', '️️️️️️️️️', '️️️️️️️️️', '️️️️️️️️️', '️️️️', '️️️️️️️️', '️️️️️️️️️️️️️️️']\n",
      "['༼', '◕\\\\', '◕', '༽']\n",
      "['⌚1145', '❤']\n",
      "['▬▬▬◙▬▬▬', '═▂▄▄▓▄▄▂', '◢◤', '█▀▀████▄▄▄▄◢◤', '█▄', '█', '█▄', '███▀▀▀▀▀▀▀╬', '◥█████◤', '══╩══╩═', '╬═╬', '╬═╬', '╬═╬', '╬═╬', '╬═╬', '╬═╬☻', '╬═╬▌', '╬═╬', '\\\\', 'just', 'dropped', 'down', '╬═╬', 'say', 'aayega', 'modi']\n",
      "['\\u2066', '\\u2066', '\\u2066', '\\u2066', '\\u2066', '\\u2066']\n",
      "['’', '’']\n"
     ]
    }
   ],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "data = []\n",
    "for i,(text,klasse) in enumerate(data_list):\n",
    "    try:\n",
    "        if len(text)>1 and detect(\" \".join(text)) == \"en\" :\n",
    "            text = [lemmatizer.lemmatize(word.lower()) for word in text if word not in stop_words]\n",
    "        \n",
    "            data.append((text,klasse))\n",
    "        else:\n",
    "            pass\n",
    "            #print(text)\n",
    "    except:\n",
    "        print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "save_data = copy.deepcopy(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (text,value) in enumerate(data):\n",
    "    for k in text:\n",
    "        if len(k)<=2:\n",
    "            text.remove(k)\n",
    "    data[i]= (text,value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "182851"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200119"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['ever',\n",
       "  'listen',\n",
       "  'like',\n",
       "  'gurukul',\n",
       "  'discipline',\n",
       "  'maintained',\n",
       "  'even',\n",
       "  'narendra',\n",
       "  'modi',\n",
       "  'maintaining',\n",
       "  'culture',\n",
       "  'indian',\n",
       "  'attack',\n",
       "  'politics',\n",
       "  'someone',\n",
       "  'attack',\n",
       "  'hinduism',\n",
       "  'take',\n",
       "  'action',\n",
       "  'proud'],\n",
       " 1.0)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic = {}\n",
    "for i, (text,value) in enumerate(data):\n",
    "    dic[i] = (text,value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(\"data.json\", \"w\") as f:\n",
    "    json.dump(dic,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ab hier mit importierten Daten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/juliangreil/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/juliangreil/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import scipy\n",
    "import random\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')\n",
    "stop_words = stopwords.words('english')\n",
    "from langdetect import detect\n",
    "import re, string\n",
    "#from gensim.models.doc2vec import Doc2Vec\n",
    "#from sentence_transformers import SentenceTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import torch.autograd as autograd         # computation graph\n",
    "from torch import Tensor \n",
    "import torch# tensor node in the computation graph\n",
    "import torch.nn as nn                     # neural networks\n",
    "import torch.nn.functional as F           # layers, activations and more\n",
    "import torch.optim as optim   \n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data.json\", \"r\") as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "descriptions_representation_tfidf = tfidf_vectorizer.fit_transform([\" \".join(text) for text, klasse in data.values()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(182851, 115859)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "descriptions_representation_tfidf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "scipy.sparse.isspmatrix(descriptions_representation_tfidf[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_rep = scipy.sparse.csr_matrix.toarray(descriptions_representation_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "rep_list = list()\n",
    "\n",
    "for i in range(data_rep.shape[0]):\n",
    "    \n",
    "    rep = data_rep[i]\n",
    "    klasse = data[str(i)][1]\n",
    "    rep_list.append((rep, klasse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(rep_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ = rep_list[:int(len(rep_list)*0.9)]\n",
    "test_ = rep_list[int(len(rep_list)*0.9):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cpu' if not torch.cuda.is_available() else 'cuda')\n",
    "def create_batches(liste, batch_size = 64, num_classes = 3):\n",
    "    \n",
    "    batches = list()\n",
    "    batch = list()\n",
    "    \n",
    "    targets = list()\n",
    "    target = list()\n",
    "    \n",
    "    for i, (d, t) in enumerate(liste):\n",
    "        if i % batch_size == 0:\n",
    "            \n",
    "            label = np.zeros(num_classes)\n",
    "            t_ = 2 if t == -1 else int(t)\n",
    "            label[t_] = 1\n",
    "            label = torch.from_numpy(label).to(device)\n",
    "            target.append(label)\n",
    "            targets.append(target)\n",
    "            \n",
    "            d = torch.from_numpy(d).to(device)\n",
    "            batch.append(d)\n",
    "            \n",
    "            batch = torch.stack(batch)\n",
    "            batches.append(batch)\n",
    "            \n",
    "            batch = list()\n",
    "            target = list()\n",
    "            \n",
    "        else:\n",
    "            d = torch.from_numpy(d).to(device)\n",
    "            batch.append(d)\n",
    "            \n",
    "            label = np.zeros(num_classes)\n",
    "            t_ = 2 if t == -1 else int(t)\n",
    "            label[t_] = 1\n",
    "            label = torch.from_numpy(label).to(device)\n",
    "            target.append(label)\n",
    "    return batches, targets\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_batches, train_targets = create_batches(train_)\n",
    "#test_batches, test_targets = create_batches(test_, batch_size = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_batches, test_targets = create_batches(test_, batch_size = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-0f7e3a0d401d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mSentiment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModules\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSentiment\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'nn' is not defined"
     ]
    }
   ],
   "source": [
    "class Sentiment(nn.Modules):\n",
    "    \n",
    "    def __init__(self, input_dim):\n",
    "        super(Sentiment, self).__init__()\n",
    "        \n",
    "        self.input_layer = nn.Linear(input_dim, input_dim//2)\n",
    "        self.hidden_layer = nn.Linear(input_dim//2, input_dim//4)\n",
    "        self.output_layer = nn.Linear(input_dim//4, 3)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        \n",
    "        x = F.relu(self.input_layer(x.float()))\n",
    "        x = F.relu(self.hidden_layer(x))\n",
    "        x = nn.Sigmoid(self.output_layer(x))\n",
    "        \n",
    "        return x\n",
    "    \n",
    "def train():\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for batch_id, batch in enumerate(train_batches):\n",
    "        target = train_targets[i]\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        out = model(batch)\n",
    "        loss = criterion(out, target)\n",
    "        \n",
    "        train_loss += loss.item()\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    return train_loss/len(train_batches)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "def test():\n",
    "    model.eval()\n",
    "    correctly_classified = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "    \n",
    "        for batch_id, batch in enumerate(test_batches):\n",
    "            target = train_targets[i]\n",
    "            \n",
    "            \n",
    "            out = model(batch)\n",
    "            \n",
    "            out = torch.argmax(out)\n",
    "            tar = torch.argmax(target)\n",
    "            \n",
    "            if out == tar:\n",
    "                correctly_classified += 1\n",
    "                \n",
    "    return correctly_classified/len(test_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_df = pd.DataFrame(columns = ['epoche', 'loss', 'accuracy'])\n",
    "for e in (50):\n",
    "    loss_ = train()\n",
    "    acc = test()\n",
    "    loss_df.loc[len(loss_df),:] = [e+1, loss_, acc]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
